{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ошибочный препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = 42\n",
    "X, y = make_regression(random_state=random_state, n_features=1, noise=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ошибочно</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.80867119249539"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_transformed = scaler.fit_transform(X_train)\n",
    "model = LinearRegression().fit(X_train_transformed, y_train)\n",
    "mean_squared_error(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Правильно</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902797546636954"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed = scaler.transform(X_test)\n",
    "mean_squared_error(y_test, model.predict(X_test_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902797546636954"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LinearRegression())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "mean_squared_error(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Утечка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_samples, n_features, n_classes = 200, 10000, 2\n",
    "rng = np.random.RandomState(42)\n",
    "X = rng.standard_normal((n_samples, n_features))\n",
    "y = rng.choice(n_classes, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ошибочно</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Неправильная предварительная обработка: преобразуются все данные\n",
    "X_selected = SelectKBest(k=25).fit_transform(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, random_state=42)\n",
    "gbc = GradientBoostingClassifier(random_state=1)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = gbc.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Правильно</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42)\n",
    "select = SelectKBest(k=25)\n",
    "X_train_selected = select.fit_transform(X_train, y_train)\n",
    "\n",
    "gbc = GradientBoostingClassifier(random_state=1)\n",
    "gbc.fit(X_train_selected, y_train)\n",
    "\n",
    "X_test_selected = select.transform(X_test)\n",
    "y_pred = gbc.predict(X_test_selected)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42)\n",
    "pipeline = make_pipeline(SelectKBest(k=25),\n",
    "                         GradientBoostingClassifier(random_state=1))\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.45+/-0.07\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(pipeline, X, y)\n",
    "print(f\"Mean accuracy: {scores.mean():.2f}+/-{scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Советы по предотвращению утечки данных:\n",
    "\n",
    "1. Всегда изначально разделяйте данные на обучающие и тестовые выборки, особенно перед любыми этапами предварительной обработки.\n",
    "\n",
    "2. Никогда не включайте тестовые данные в методы <code>fit</code> и <code>fit_transform</code>. Использование всех данных мягко говоря, может привести к чрезмерно оптимистичным оценкам. </br>\n",
    "И наоборот, метод <code>transform</code> следует использовать как для обучающих, так и для тестовых выборок, поскольку ко всем данным должна применяться одинаковая предварительная обработка. Этого можно достичь, используя <code>fit_transform</code> в обучающей выборке и <code>transform</code> в тестовой.\n",
    "\n",
    "3. Конвейер scikit-learn - отличный способ предотвратить утечку данных, поскольку он гарантирует, что соответствующий метод выполняется на правильном выборке. Конвейер идеально подходит для использования в функциях перекрестной проверки и настройки гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Контроль \"случайности\"\n",
    "\n",
    "Алгоритмы используемые в scikit-learn часто, по своей сути, случайны. Например, RandomForestClassifier и  KFold. \"Случайность\" этих алгоритмов контролируется с помощью их параметра <code>random_state</code>\n",
    "\n",
    "\n",
    "Для  надежности результатов перекрестной проверки (CV) оставьте <code>random_state</code> равным <code>None</code> или целому числу. \n",
    "\n",
    "Передача целых чисел в валидацию CV обычно является самым безопасным и предпочтительным вариантом. \n",
    "\n",
    "Передача экземпляров RandomState <code>train_test_split</code> иногда может быть полезна для достижения одинакового результата использования. \n",
    "\n",
    "И для CV, и для Split передача целого числа по сравнению с передачей экземпляра (или None) приводит к тонким, но значительным различиям вычислительных продцедур, особенно для процедур CV. Эти различия важно понимать при анализе результатов моделели.\n",
    "\n",
    "Для воспроизводимости результатов вычислений необходимо исключить любое использование <code>random_state = None</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.85418642  4.79084103 -3.13077794  8.11915045 -0.56479934]]\n",
      "[[ 6.70814003  5.25291366 -7.55212743  5.18197458  1.37845099]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "X, y = make_classification(n_features=5, random_state=rng)\n",
    "sgd = SGDClassifier(random_state=rng)\n",
    "\n",
    "print( sgd.fit(X, y).coef_)\n",
    "print( sgd.fit(X, y).coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-19.16369217  10.14644031   0.60707996   0.56520545  24.43565214]]\n",
      "[[-19.16369217  10.14644031   0.60707996   0.56520545  24.43565214]]\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_features=5, random_state=8)\n",
    "sgd = SGDClassifier(random_state=12)\n",
    "\n",
    "print( sgd.fit(X, y).coef_)\n",
    "print( sgd.fit(X, y).coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 5 6 7] [1 2 4 8 9]\n",
      "[1 2 4 8 9] [0 3 5 6 7]\n",
      "[0 4 6 7 8] [1 2 3 5 9]\n",
      "[1 2 3 5 9] [0 4 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "X = y = np.arange(10)\n",
    "rng = np.random.RandomState(0)\n",
    "cv = KFold(n_splits=2, shuffle=True, random_state=rng)\n",
    "\n",
    "for train, test in cv.split(X, y):\n",
    "    print(train, test)\n",
    "\n",
    "for train, test in cv.split(X, y):\n",
    "    print(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И еще о \"подводных камнях\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85 0.95 0.95 0.9  0.9 ]\n",
      "[0.9  0.95 0.95 0.9  0.9 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_classification(random_state=0)\n",
    "\n",
    "rf_123 = RandomForestClassifier(random_state=123)\n",
    "print(cross_val_score(rf_123, X, y))\n",
    "\n",
    "\n",
    "rf_inst = RandomForestClassifier(random_state=np.random.RandomState(0))\n",
    "print(cross_val_score(rf_inst, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что результаты перекрестной проверки rf_123 и rf_inst различаются, как и следовало ожидать, поскольку мы не передали один и тот же параметр random_state. Однако разница между этими оценками более тонкая, чем кажется, и процедуры перекрестной проверки, которые выполнялись с помощью cross_val_score, значительно различаются в каждом случае:\n",
    "\n",
    "Поскольку rf_123 было передано целое число, каждый вызов функции fit использует один и тот же RNG: это означает, что все случайные характеристики случайного оценщика леса будут одинаковыми для каждого из 5 кратностей процедуры CV. <b>В частности, (случайно выбранное) подмножество функций оценщика будет одинаковым для всех подвыборок.</b>\n",
    "\n",
    "Поскольку rf_inst был передан экземпляр RandomState, каждый вызов для соответствия начинается с другого RNG. В результате случайный набор функций будет отличаться для каждой подвыбороки.\n",
    "\n",
    "Хотя наличие постоянного оценщика RNG по подвыборокам не является неправильным по своей сути, мы обычно хотим, чтобы результаты CV были надежными по отношению к \"случайности\" оценщика. В результате передача экземпляра  RandomState вместо целого числа может быть предпочтительнее, поскольку это позволит оценцику изменяться для каждой подвыборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Клонирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9  0.95 0.95 0.9  0.9 ]\n",
      "[0.9  0.95 0.95 0.9  0.9 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import clone\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_classification(random_state=0)\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "a = RandomForestClassifier(random_state=rng)\n",
    "b = clone(a)\n",
    "\n",
    "print(cross_val_score(a, X, y))\n",
    "print(cross_val_score(b, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Клоны не являются копиями в прямом сысле слова - это не два различных одинаковых объекта, это один объект с двумя именами, они ссылаются на один и тотже объект. Если бы было передано целое число, a и b были бы точными клонами, и они не влияли бы друг на друга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Многократная повторяемость результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(18)\n",
    "X, y = make_classification(random_state=rng)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=rng)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=rng)\n",
    "rf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно! Не устанавливайте в вашем коде np.random.RandomState(0) дискуссия тут https://stackoverflow.com/questions/5836335/consistently-create-same-random-numpy-array/5837352#comment6712034_5837352\n",
    "\n",
    "Кстати, а почему всегда одинаково и почему так лучше, чем передать целое число?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
